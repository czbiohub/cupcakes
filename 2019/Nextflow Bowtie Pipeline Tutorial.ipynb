{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nextflow Bowtie Pipeline Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set Up Nextflow Enivornment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a conda environment and install Nextflow\n",
    "- `conda create -n nextflow`\n",
    "- `source activate nextflow`\n",
    "- `conda install -c bioconda nextflow`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone nf-bowtie github repository\n",
    "- `git clone https://github.com/czbiohub/nf-bowtie.git`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Docker (if you want to run nextflow locally)\n",
    "- https://docs.docker.com/docker-for-mac/install/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. nf-bowtie inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline can take different inputs for the reference file:\n",
    "    - Single fasta (--reference_type single_file)\n",
    "    - A folder of fasta references to bowtie against (--reference_type folder)\n",
    "    - Nested folders (--reference_type embedded_folder)\n",
    "        - For example:\n",
    "            - /mnt/data/sample1\n",
    "                - /mnt/data/sample1/contigs.fasta\n",
    "            - /mnt/data/sample2\n",
    "                - /mnt/data/sample2/contigs.fasta\n",
    "            - /mnt/data/sample3\n",
    "                - /mnt/data/sample3/contigs.fasta\n",
    "                \n",
    "The reads can either be in a `.fastq` or `.fastq.gz` form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Typical Bowtie Command Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical structure:\n",
    "\n",
    "```\n",
    "nextflow run main.nf -profile czbiohub_aws --skip_fastqc  --skip_count false\n",
    "\n",
    "--reference_type single_file --reads ‘<read_folder>/**{R1,R2}_001.fastq’\n",
    "\n",
    " --reference ‘<reference_folder>/<sample>.fasta’\n",
    "\n",
    "--outdir ’<output_directory>’```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* -- skip_fastqc: stops the fastqc process which QCs all you read files you push into the alignment pipeline\n",
    "* --skip_count false: counts are usually off but this allows you to turn it on\n",
    "* --reads: path to reads\n",
    "* --reference: path to reference\n",
    "* --outdir: specify an output directory or just let it default to placing the output in `./results`\n",
    "* -profile: you can have the pipeline running in aws batch using `czbiohub_aws` or locally on your computer using `local`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run and edit the Makefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makefiles are amazing. Take a look at the Makefile (I suggest cd-ing into the nf-bowtie repository you cloned and then calling `atom .`) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "demo1:\n",
    "\tnextflow run main.nf -profile czbiohub_aws \\\\\n",
    "    --skip_fastqc --reference_type single_file \\\\\n",
    "    --reads 's3://kalani-bucket/FLASH/fastq/**{R1,R2}_001.fastq' \\\\\n",
    "    --reference \\\\\n",
    "    's3://kalani-bucket/FLASH/amrFLASH_all_98percent_1433.fasta' \\\\\n",
    "    --outdir './results_flash_demo1'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the command associated with `demo 1`, it looks pretty complicated. But I can edit the command on atom (or nano while on terminal) and run it by just typing `Make demo1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `cat nextflow.config` in wherever directory you ran your nextflow command to see where it stopped\n",
    "- aws batch interface\n",
    "    - Can ID the jobs that were submitted to see if they were running, succeeded, failed or stalling\n",
    "    - Use the job ID to go to cloudwatch and understand the reason a job might have failed\n",
    "- pipeline info folders in your `result` folder can let you know which processes worked and which ones didn't"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Making your own Nextflow Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take a look at Olga's repository on starting with Nextflow (section entitled `Creating your own Nextflow Workflow`): https://github.com/czbiohub/nextflow-tutorial-2019\n",
    "- https://github.com/nf-core/tools\n",
    "- I also really like this page for common commands and patterns if you need help with certain parts of your processes: http://nextflow-io.github.io/patterns/index.html\n",
    "- post on #eng-support and #nextflow on slack for questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
